"""
Mixtral 8x7B Instruct free api key from openrouter

response time to answer sequentially the 5 propmpts -> 30 seconds
"""
from openai import OpenAI
from dotenv import load_dotenv
import sys
import os

# Append the src/traffic_ai folder to sys.path
current_dir = os.path.dirname(__file__)
parent_dir = os.path.abspath(os.path.join(current_dir, "..", ".."))  # this points to traffic_ai/
sys.path.append(parent_dir)

from traffic_ai.traffic_forecast.traffic_prediction_json_bldr import *
from traffic_ai.traffic_recommendation.traffic_data_summarizer import *
from traffic_ai.traffic_recommendation.traffic_prompt_bldr import *

def config():
  load_dotenv()

class AIRecommendation:
  def __init__(self):
    # prompt handler
    self.prompt = {
      'sp': None,
      'hp': None,
      'dp': None,
      'wp': None,
      'mp': None,
    }

    # ai generated recommendation hand;er variables
    self.pred_ai_recommendation = {
      'summary_reco': None,
      'hourly_reco': None,
      'daily_reco': None,
      'weekly_reco': None,
      'monthly_reco': None
    }

    # handler for user request recommendation
    self.req_ai_recommendation = None

    # initialize client
    config()

    self.client = OpenAI(
      base_url="https://openrouter.ai/api/v1",
      api_key=os.getenv('AI_API_KEY'),
    )

    # cd to cache dir
    self.CACHE_DIR = Path(__file__).resolve().parents[3] / 'cache'
    # create cache file json
    self.ADMIN_CACHE_FILE = CACHE_DIR / 'daily_admin_traffic_recommendation.json'
    self.END_USER_CACHE_FILE = CACHE_DIR / 'daily_end_user_traffic_recommendation.json'
    # handles recommendationn as json and cache
    self.reco_json = {}


  def client_chat(self, prompt):
    self.completion = self.client.chat.completions.create(
      model="mistralai/mixtral-8x7b-instruct",
      messages=[
        {
          "role": "user",
          "content": prompt
        }
      ]
    )

    return self.completion


  """Determine user type and return cache file accordingly"""
  def _get_cache_file(self, user_type):
    admin_roles = {"admin", "traffic_enforcer", "city_engineer"}
    return self.ADMIN_CACHE_FILE if user_type in admin_roles else self.END_USER_CACHE_FILE


  """
  checks if traffic recommendation today exists or fresh content
  if today's date and the date the file was modified is same, return true (meaning the file's content is fresh)
  """
  def recommendation_today_exists(self, user_type):
    cache_file = self._get_cache_file(user_type)
    if not cache_file.exists():
      return False
    # checks the last time when the file was edited
    modified_time = datetime.fromtimestamp(self.ADMIN_CACHE_FILE.stat().st_mtime)
    return modified_time.date() == datetime.today().date() 
  

  """Load today's cached recommendation into memory."""
  def load_today_cache(self, user_type):
    cache_file = self._get_cache_file(user_type)
    with open(cache_file, 'r') as f:
      self.reco_json = json.load(f)
      self.pred_ai_recommendation = dict(self.reco_json)


  """generate recommendation for traffic data/summaries"""
  def generate_recommendations(self, d1, d2, user_type):
    # get summary of traffic data generated by prophet
    sum_s = sum_summary(d1)
    hour_s = hourly_summary(d2)
    day_s = daily_summary(d2)
    week_s = weekly_summary(d2)
    month_s = monthly_summary(d2)
 
    # build prompt
    self.prompt = {
      'sp': summary_prompt(sum_s, user_type),
      'hp': hourly_prompt(hour_s, user_type),
      'dp': daily_prompt(day_s, user_type),
      'wp': weekly_prompt(week_s, user_type),
      'mp': monthly_prompt(month_s, user_type),
    }

    for (key, prompt) in zip(self.pred_ai_recommendation.keys(), self.prompt.values()):
      # call api and generate recommendation
      try:
        print("Delivering AI Traffic Recommendations...\n\n")
        # pass the prompt to ai
        comp = self.client_chat(prompt)

        ai_output = comp.choices[0].message.content
        # pass as value the ai generated recommendation to the dictionary
        self.pred_ai_recommendation[key] = ai_output

        # add prompt key as reco_json key and value is the recommendation
        self.reco_json[key] = ai_output
      except Exception as e:
        raise ConnectionError(f"Failed client connection: {e}")
      
    # convert the dict into json and save to cache file
    cache_file = self._get_cache_file(user_type)
    self.CACHE_DIR.mkdir(parents=True, exist_ok=True)
    with open(cache_file, 'w') as f:
      json.dump(self.reco_json, f, indent=2)

    return self.reco_json
  

  """Main entry point for getting today's recommendations."""
  def run_ai_recommendation(self, d1, d2, user_type):
    if self.recommendation_today_exists(user_type):
      self.load_today_cache(user_type)
    else:
      self.generate_recommendations(d1, d2, user_type)


  def traffic_request_reco(self, prediction: dict, user_type: str):
    # validate user request schema structure to the passed user type
    if not {'start', 'end'}.issubset(prediction.get('request_date', {})):
      user_type = 'end_user'

    # pass request data to the summarizer and prompt bldr based on user type
    summary = admin_req_summary(prediction) if not user_type == 'end_user' else end_user_req_summary(prediction)
    request_prompt = admin_request_prompt(summary) if not user_type == 'end_user' else user_request_prompt(summary)

    # call api and generate recommendation
    try:
      print("Delivering AI Traffic Recommendations...\n\n")
      comp = self.client_chat(request_prompt)
      self.req_ai_recommendation = comp.choices[0].message.content
    except Exception as e:
        raise ConnectionError(f"Failed client connection: {e}")
    
    return self.req_ai_recommendation


def main():
  d1 = prediction_summary()
  d2 = prediction_detail() 

  req1 = {
    "start": "2025-09-09T05:00:00",
    "end": "2025-10-22T10:00:00"
  }

  req2 = {
    'time': "2025-10-09T12:00:00"
  }

  d3 = user_prediction_req(req2)
  d4 = admin_prediction_req(req1)

  reco = AIRecommendation()

  reco.run_ai_recommendation(d1, d2, 'city_engineer')
  r = reco.reco_json

  print(json.dumps(r, indent=2))

  r2 = reco.traffic_request_reco(d4, 'traffic_enforcer')
  print("\n\n\n",r2)

if __name__ == "__main__":
  main()